{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Install required packages**"
      ],
      "metadata": {
        "id": "Lem0-BE7VBgY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdewudUk-x5X",
        "outputId": "23ef1189-1d2b-4909-93e9-ab94b2042328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.106.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.31.1\n"
          ]
        }
      ],
      "source": [
        "!pip install groq openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Libraries**"
      ],
      "metadata": {
        "id": "MQlZylUhVNx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "from groq import Groq\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "lb0fSXvE_s_i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setting up API Key and Client**"
      ],
      "metadata": {
        "id": "gIwYbs6iVS6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = \"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\"\n",
        "client = Groq(api_key=GROQ_API_KEY)"
      ],
      "metadata": {
        "id": "nL1Ub5Qx_wtc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating classes and functions for Conversation Manager (Task 1)**"
      ],
      "metadata": {
        "id": "snILcEaCVpJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ConversationConfig:\n",
        "    max_turns: int = 10  # Default: keep last 10 messages\n",
        "    max_chars: int = 2000  # Default: 2000 characters\n",
        "    summarize_every: int = 3  # Summarize every 3rd run\n",
        "    model: str = \"llama-3.1-8b-instant\"  # llama model"
      ],
      "metadata": {
        "id": "UwGLph9bA3QW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "import time\n",
        "\n",
        "@dataclass\n",
        "class ConversationConfig:\n",
        "    max_turns: int = 10\n",
        "    max_chars: int = 2000\n",
        "    summarize_every: int = 3\n",
        "    model: str = \"llama-3.1-8b-instant\"\n",
        "\n",
        "class ConversationManager:\n",
        "    def __init__(self, config: ConversationConfig = None):\n",
        "        self.config = config or ConversationConfig()\n",
        "        self.conversation_history: List[Dict[str, str]] = []\n",
        "        self.run_count = 0\n",
        "        self.summaries: List[str] = []\n",
        "\n",
        "    def add_message(self, role: str, content: str):\n",
        "        \"\"\"Add a message to conversation history\"\"\"\n",
        "        self.conversation_history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "    def get_history(self, limit_turns: Optional[int] = None, limit_chars: Optional[int] = None):\n",
        "        \"\"\"Get conversation history with optional truncation\"\"\"\n",
        "        history = self.conversation_history.copy()\n",
        "\n",
        "        # Apply turn-based truncation\n",
        "        if limit_turns is not None and len(history) > limit_turns:\n",
        "            history = history[-limit_turns:]\n",
        "        elif self.config.max_turns and len(history) > self.config.max_turns:\n",
        "            history = history[-self.config.max_turns:]\n",
        "\n",
        "        # Apply character-based truncation\n",
        "        if limit_chars is not None:\n",
        "            history = self._truncate_by_chars(history, limit_chars)\n",
        "        elif self.config.max_chars:\n",
        "            history = self._truncate_by_chars(history, self.config.max_chars)\n",
        "\n",
        "        return history\n",
        "\n",
        "    def _truncate_by_chars(self, history: List[Dict[str, str]], max_chars: int):\n",
        "        \"\"\"Truncate conversation history by character length\"\"\"\n",
        "        truncated_history = []\n",
        "        current_length = 0\n",
        "\n",
        "        for message in reversed(history):\n",
        "            message_length = len(message[\"content\"])\n",
        "            if current_length + message_length <= max_chars:\n",
        "                truncated_history.insert(0, message)\n",
        "                current_length += message_length\n",
        "            else:\n",
        "                # Add partial message if there's significant content space\n",
        "                remaining_chars = max_chars - current_length\n",
        "                if remaining_chars > 20:\n",
        "                    partial_message = message.copy()\n",
        "                    partial_message[\"content\"] = message[\"content\"][:remaining_chars] + \"...\"\n",
        "                    truncated_history.insert(0, partial_message)\n",
        "                break\n",
        "\n",
        "        return truncated_history\n",
        "\n",
        "    def summarize_conversation(self):\n",
        "        \"\"\"Generate a summary of the conversation history\"\"\"\n",
        "        if not self.conversation_history:\n",
        "            return \"No conversation to summarize.\"\n",
        "\n",
        "        # Create a simplified version for summarization\n",
        "        conversation_text = \"\\n\".join([\n",
        "            f\"{msg['role'].capitalize()}: {msg['content']}\"\n",
        "            for msg in self.conversation_history\n",
        "        ])\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Please provide a concise summary of the following conversation.\n",
        "        Focus on the key points, decisions made, and important information exchanged.\n",
        "        Keep the summary under 150 words.\n",
        "\n",
        "        Conversation:\n",
        "        {conversation_text}\n",
        "\n",
        "        Summary:\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=self.config.model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.3,\n",
        "                max_tokens=300\n",
        "            )\n",
        "\n",
        "            summary = response.choices[0].message.content.strip()\n",
        "            self.summaries.append(summary)\n",
        "            return summary\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error generating summary: {str(e)}\"\n",
        "\n",
        "    def run_conversation(self, user_input: str):\n",
        "        \"\"\"Process user input and manage conversation with periodic summarization\"\"\"\n",
        "        if not client:\n",
        "            return \"Error: Groq client not initialized. Please check your API key.\"\n",
        "\n",
        "        self.run_count += 1\n",
        "\n",
        "        # Add user message to history\n",
        "        self.add_message(\"user\", user_input)\n",
        "\n",
        "        # Check if it's time to summarize\n",
        "        should_summarize = self.run_count % self.config.summarize_every == 0\n",
        "        summary_added = False\n",
        "\n",
        "        if should_summarize and len(self.conversation_history) > 1:\n",
        "            summary = self.summarize_conversation()\n",
        "            if not summary.startswith(\"Error\"):\n",
        "                # Store summary and keep only recent context\n",
        "                self.conversation_history = [\n",
        "                    {\"role\": \"system\", \"content\": f\"Previous conversation summary: {summary}\"},\n",
        "                    {\"role\": \"user\", \"content\": user_input}\n",
        "                ]\n",
        "                summary_added = True\n",
        "\n",
        "        # Get truncated history for the API call\n",
        "        current_history = self.get_history()\n",
        "\n",
        "        try:\n",
        "            # Generate assistant response\n",
        "            response = client.chat.completions.create(\n",
        "                model=self.config.model,\n",
        "                messages=current_history,\n",
        "                temperature=0.7,\n",
        "                max_tokens=500\n",
        "            )\n",
        "\n",
        "            assistant_response = response.choices[0].message.content\n",
        "            self.add_message(\"assistant\", assistant_response)\n",
        "\n",
        "            # Add summary note to response if applicable\n",
        "            if should_summarize and summary_added:\n",
        "                assistant_response = f\"[Summary generated] {assistant_response}\"\n",
        "\n",
        "            return assistant_response\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error in conversation: {str(e)}\"\n",
        "            self.add_message(\"system\", error_msg)\n",
        "            return error_msg\n",
        "\n",
        "    def get_history_stats(self):\n",
        "        \"\"\"Get statistics about the current conversation history\"\"\"\n",
        "        history = self.get_history()\n",
        "        total_chars = sum(len(msg[\"content\"]) for msg in history)\n",
        "        return {\n",
        "            \"message_count\": len(history),\n",
        "            \"total_chars\": total_chars,\n",
        "            \"summaries_count\": len(self.summaries)\n",
        "        }"
      ],
      "metadata": {
        "id": "4KgmhAKzA4Ut"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Demonstration for Task 1**"
      ],
      "metadata": {
        "id": "Y0b0OEI5VbAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstration of Task 1\n",
        "print(\"=== Task 1 Demonstration: Conversation Management with Summarization ===\")\n",
        "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "# Create conversation manager with custom configuration\n",
        "config = ConversationConfig(\n",
        "    max_turns=5,\n",
        "    max_chars=1500,\n",
        "    summarize_every=3,  # Summarize after every 3rd run\n",
        "    model=\"llama-3.1-8b-instant\"\n",
        ")\n",
        "\n",
        "convo_manager = ConversationManager(config)\n",
        "\n",
        "# Sample conversation turns\n",
        "conversation_samples = [\n",
        "    \"Hi, tell me about today's weather?\",\n",
        "    \"Should I carry an umbrella?\",\n",
        "    \"What is the capital of India?\",\n",
        "    \"What are some of India's State?\",\n",
        "    \"Tell me about some new Smartphones?\",\n",
        "    \"What is an LLM?\",\n",
        "    \"What is GROQ?\",\n",
        "    \"Which is the most used programming language?\",\n",
        "    \"Is Python better or R?\",\n",
        "    \"Difference between Machine Learning and Artificial Intelligence?\"\n",
        "]\n",
        "\n",
        "print(\"Running conversation with periodic summarization (every 3 turns):\\n\")\n",
        "\n",
        "# Run the conversation\n",
        "for i, user_input in enumerate(conversation_samples, 1):\n",
        "    print(f\"Run {i}:\")\n",
        "    print(f\"User: {user_input}\")\n",
        "\n",
        "    # Add delay to avoid rate limiting\n",
        "    if i > 1:\n",
        "        time.sleep(1)\n",
        "\n",
        "    response = convo_manager.run_conversation(user_input)\n",
        "    print(f\"Assistant: {response}\")\n",
        "\n",
        "    # Show history stats after each run\n",
        "    stats = convo_manager.get_history_stats()\n",
        "    print(f\"History: {stats['message_count']} messages, {stats['total_chars']} chars\")\n",
        "\n",
        "    # Show when summarization happens\n",
        "    if i % config.summarize_every == 0:\n",
        "        print(f\"📝 Summary generated after {i} runs!\")\n",
        "        if convo_manager.summaries:\n",
        "            print(f\"Latest summary: {convo_manager.summaries[-1][:100]}...\")\n",
        "\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "# Demonstrate different truncation settings\n",
        "print(\"\\n=== Truncation Settings Demonstration ===\")\n",
        "\n",
        "# Test 1: Turn-based truncation\n",
        "print(\"\\n1. Turn-based truncation (last 3 messages):\")\n",
        "truncated_turns = convo_manager.get_history(limit_turns=3)\n",
        "for msg in truncated_turns:\n",
        "    role = msg['role'].ljust(10)\n",
        "    content = msg['content'][:70] + \"...\" if len(msg['content']) > 70 else msg['content']\n",
        "    print(f\"{role}: {content}\")\n",
        "\n",
        "# Test 2: Character-based truncation\n",
        "print(\"\\n2. Character-based truncation (500 chars):\")\n",
        "truncated_chars = convo_manager.get_history(limit_chars=500)\n",
        "total_chars = sum(len(msg[\"content\"]) for msg in truncated_chars)\n",
        "print(f\"Total characters: {total_chars}\")\n",
        "for msg in truncated_chars:\n",
        "    role = msg['role'].ljust(10)\n",
        "    content = msg['content'][:70] + \"...\" if len(msg['content']) > 70 else msg['content']\n",
        "    print(f\"{role}: {content}\")\n",
        "\n",
        "# Test 3: Combined truncation (turns + chars)\n",
        "print(\"\\n3. Combined truncation (last 4 messages, max 800 chars):\")\n",
        "truncated_combined = convo_manager.get_history(limit_turns=4, limit_chars=800)\n",
        "total_chars = sum(len(msg[\"content\"]) for msg in truncated_combined)\n",
        "print(f\"Total characters: {total_chars}\")\n",
        "for msg in truncated_combined:\n",
        "    role = msg['role'].ljust(10)\n",
        "    content = msg['content'][:70] + \"...\" if len(msg['content']) > 70 else msg['content']\n",
        "    print(f\"{role}: {content}\")\n",
        "\n",
        "# Show all summaries generated\n",
        "print(\"\\n=== All Summaries Generated ===\")\n",
        "for i, summary in enumerate(convo_manager.summaries, 1):\n",
        "    print(f\"\\nSummary {i}:\")\n",
        "    print(summary[:200] + \"...\" if len(summary) > 200 else summary)\n",
        "\n",
        "# Show final conversation history\n",
        "print(\"\\n=== Final Conversation History ===\")\n",
        "stats = convo_manager.get_history_stats()\n",
        "print(f\"Final stats: {stats['message_count']} messages, {stats['total_chars']} chars, {stats['summaries_count']} summaries\")\n",
        "for i, msg in enumerate(convo_manager.get_history()):\n",
        "    role = msg['role'].ljust(10)\n",
        "    content = msg['content'][:100] + \"...\" if len(msg['content']) > 100 else msg['content']\n",
        "    print(f\"{i+1:2d}. {role}: {content}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2woO7Mc7FQvP",
        "outputId": "289d5948-0eb2-4cc2-d613-babcb800d1f9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Task 1 Demonstration: Conversation Management with Summarization ===\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Running conversation with periodic summarization (every 3 turns):\n",
            "\n",
            "Run 1:\n",
            "User: Hi, tell me about today's weather?\n",
            "Assistant: However, I'm a large language model, I don't have real-time access to current weather information. But I can suggest some options to help you find out the weather for your location:\n",
            "\n",
            "1. **Check online weather websites**: You can visit websites like AccuWeather, Weather.com, or the National Weather Service (NWS) for current weather conditions and forecasts.\n",
            "2. **Use a mobile app**: Download a weather app on your smartphone, such as Dark Sky or Weather Underground, which can provide you with current weather conditions and forecasts.\n",
            "3. **Ask a voice assistant**: If you have a smart speaker or virtual assistant like Siri, Google Assistant, or Alexa, you can ask them to tell you the current weather.\n",
            "\n",
            "Please let me know if there's anything else I can help you with.\n",
            "History: 2 messages, 804 chars\n",
            "----------------------------------------------------------------------\n",
            "Run 2:\n",
            "User: Should I carry an umbrella?\n",
            "Assistant: To determine if you should carry an umbrella, I'd need to know the location and current weather conditions. As I mentioned earlier, I don't have real-time access to current weather information.\n",
            "\n",
            "However, I can suggest a few general guidelines to help you decide:\n",
            "\n",
            "1. **Check the forecast**: As I mentioned earlier, you can check online weather websites or mobile apps to see if there's a chance of rain or other precipitation in your area.\n",
            "2. **Look for cloud cover**: If you can see dark or thick clouds in the sky, it's a good idea to carry an umbrella.\n",
            "3. **Check the wind**: If there's a strong wind, umbrellas might be more difficult to use, so you might want to consider other options, such as a raincoat or poncho.\n",
            "\n",
            "If you're still unsure, you could always err on the side of caution and carry an umbrella, just in case.\n",
            "History: 3 messages, 1503 chars\n",
            "----------------------------------------------------------------------\n",
            "Run 3:\n",
            "User: What is the capital of India?\n",
            "Assistant: [Summary generated] The capital of India is New Delhi. It is located in the northern part of the country and serves as the seat of the government and the residence of the President of India.\n",
            "History: 3 messages, 996 chars\n",
            "📝 Summary generated after 3 runs!\n",
            "Latest summary: Here's a concise summary of the conversation:\n",
            "\n",
            "The conversation started with the user asking about t...\n",
            "----------------------------------------------------------------------\n",
            "Run 4:\n",
            "User: What are some of India's State?\n",
            "Assistant: India is a vast and diverse country with 28 states and 8 union territories. Here's a list of some of the prominent states in India:\n",
            "\n",
            "1. Andhra Pradesh: Located in southeastern India, known for its rich cultural heritage and delicious cuisine.\n",
            "2. Arunachal Pradesh: A northeastern state with stunning natural beauty and a diverse range of flora and fauna.\n",
            "3. Assam: Located in northeastern India, famous for its tea plantations, wildlife, and cultural festivals.\n",
            "4. Bihar: A state in eastern India, known for its ancient history, cultural significance, and rich spiritual heritage.\n",
            "5. Chhattisgarh: A state in central India, famous for its natural resources, tribal cultures, and historic sites.\n",
            "6. Goa: A coastal state in western India, known for its beautiful beaches, vibrant nightlife, and colonial architecture.\n",
            "7. Gujarat: A state in western India, famous for its rich cultural heritage, delicious cuisine, and historical sites.\n",
            "8. Haryana: A state in northern India, known for its rich history, cultural significance, and diverse wildlife.\n",
            "9. Himachal Pradesh: A state in northern India, famous for its breathtaking natural beauty, adventure sports, and spiritual sites.\n",
            "10. Jammu and Kashmir: A state in northern India, known for its stunning natural beauty, rich cultural heritage, and spiritual significance.\n",
            "11. Jharkhand: A state in eastern India, famous for its rich natural resources, diverse wildlife, and tribal cultures.\n",
            "12. Karnataka: A state in southern India, known for its rich cultural heritage, historical sites, and vibrant cities.\n",
            "13. Kerala: A state in southern India, famous for its stunning natural beauty, traditional arts, and delicious cuisine.\n",
            "14. Madhya Pradesh: A state in central India, known for its rich cultural heritage, historical sites, and diverse wildlife.\n",
            "15. Maharashtra: A state in western India, famous for its vibrant cities, rich cultural heritage, and historical sites.\n",
            "16. Manipur: A state in northeastern India, known for its rich cultural heritage, traditional arts, and diverse wildlife.\n",
            "17. Meghalaya: A state in northeastern India, famous for its stunning natural beauty, traditional arts, and vibrant culture.\n",
            "18. Mizoram: A state in northeastern India, known for its stunning natural beauty, traditional arts, and diverse wildlife.\n",
            "19. Nagaland: A state in northeastern India, famous for its rich cultural heritage, traditional arts, and diverse\n",
            "History: 1 messages, 1503 chars\n",
            "----------------------------------------------------------------------\n",
            "Run 5:\n",
            "User: Tell me about some new Smartphones?\n",
            "Assistant: There have been several recent smartphone releases across various brands. Here are a few examples:\n",
            "\n",
            "1. **Samsung Galaxy S23 Series**:\n",
            "- Released in February 2023, the Samsung Galaxy S23, S23+, and S23 Ultra feature improved cameras, larger batteries, and faster processors.\n",
            "- The S23 Ultra boasts a 6.8-inch Dynamic AMOLED display, up to 16GB of RAM, and a long-lasting 5000mAh battery.\n",
            "\n",
            "2. **Apple iPhone 14 Series**:\n",
            "- Released in September 2022, the iPhone 14, 14 Plus, 14 Pro, and 14 Pro Max feature improved cameras, faster processors, and longer battery life.\n",
            "- The iPhone 14 Pro and Pro Max have a 6.1-inch Super Retina XDR display, up to 16GB of RAM, and a long-lasting 4323mAh battery.\n",
            "\n",
            "3. **Google Pixel 7 Series**:\n",
            "- Released in October 2022, the Google Pixel 7 and 7 Pro feature improved cameras, faster processors, and timely software updates.\n",
            "- The Pixel 7 Pro has a 6.7-inch OLED display, up to 12GB of RAM, and a long-lasting 5124mAh battery.\n",
            "\n",
            "4. **OnePlus 11**:\n",
            "- Released in January 2023, the OnePlus 11 features a 6.7-inch AMOLED display, up to 16GB of RAM, and a long-lasting 5000mAh battery.\n",
            "- It also comes with improved cameras and a faster processor.\n",
            "\n",
            "5. **Xiaomi 13 Series**:\n",
            "- Released in December 2022, the Xiaomi 13 and 13 Pro feature improved cameras, faster processors, and longer battery life.\n",
            "- The Xiaomi 13 Pro has a 6.73-inch AMOLED display, up to 12GB of RAM, and a long-lasting 4820mAh battery.\n",
            "\n",
            "Please note that these are just a few examples, and new smartphones are released regularly. The specifications and features may also vary depending on the region and retailer.\n",
            "History: 1 messages, 1503 chars\n",
            "----------------------------------------------------------------------\n",
            "Run 6:\n",
            "User: What is an LLM?\n",
            "Assistant: [Summary generated] An LLM stands for Large Language Model. It's a type of artificial intelligence (AI) designed to process and understand human language at a massive scale. These models are trained on vast amounts of text data, allowing them to generate human-like text responses, summarize long pieces of text, and even translate languages.\n",
            "\n",
            "Large Language Models work by learning patterns and relationships within the text data they're trained on. They use this knowledge to predict the next word or sequence of words in a sentence or piece of text, making them highly effective at tasks such as:\n",
            "\n",
            "1. Language translation\n",
            "2. Text summarization\n",
            "3. Sentiment analysis (determining the emotional tone of text)\n",
            "4. Question answering\n",
            "5. Conversation generation (like our conversation!)\n",
            "\n",
            "There are several types of LLMs, including:\n",
            "\n",
            "1. Generative models: These models can generate new text based on a prompt or input.\n",
            "2. Discriminative models: These models can classify or categorize text based on its content.\n",
            "3. Hybrid models: These models combine elements of both generative and discriminative models.\n",
            "\n",
            "In our conversation, I'm an example of a conversational AI that uses LLM technology to understand and respond to your questions and prompts.\n",
            "\n",
            "LLMs are a rapidly evolving field, and researchers continue to improve their performance, accuracy, and capabilities.\n",
            "History: 3 messages, 1503 chars\n",
            "📝 Summary generated after 6 runs!\n",
            "Latest summary: Here's a concise summary of the conversation:\n",
            "\n",
            "The conversation started with the user asking about t...\n",
            "----------------------------------------------------------------------\n",
            "Run 7:\n",
            "User: What is GROQ?\n",
            "Assistant: GROQ stands for GraphQL Object Query Language. It's a query language used for retrieving data from a GraphQL schema. GROQ is specifically designed for querying and manipulating data in a graph database, but it can also be used with other data stores.\n",
            "\n",
            "In a GraphQL schema, data is organized as a graph, where each node represents an entity, and edges represent relationships between entities. GROQ allows you to query this graph data using a declarative syntax, making it easier to retrieve the data you need.\n",
            "\n",
            "With GROQ, you can perform complex queries by specifying the nodes and edges you're interested in, as well as the data you want to retrieve. GROQ also supports filtering, sorting, and paginating data, making it a powerful tool for data retrieval and manipulation.\n",
            "\n",
            "Some key features of GROQ include:\n",
            "\n",
            "1. Declarative syntax: You specify what data you want to retrieve, and GROQ figures out how to get it.\n",
            "2. Graph-based querying: GROQ is designed to work with graph databases, but it can also be used with other data stores.\n",
            "3. Support for filtering, sorting, and pagination: GROQ makes it easy to refine and manipulate the data you retrieve.\n",
            "4. Efficient querying: GROQ is optimized for performance, making it suitable for large-scale data sets.\n",
            "\n",
            "GROQ is often used in conjunction with GraphQL, which provides a more intuitive and flexible way to query data. Together, GROQ and GraphQL enable developers to build more efficient and scalable data APIs.\n",
            "\n",
            "If you're working with graph databases or GraphQL, GROQ is definitely worth checking out!\n",
            "History: 1 messages, 1503 chars\n",
            "----------------------------------------------------------------------\n",
            "Run 8:\n",
            "User: Which is the most used programming language?\n",
            "Assistant: Determining the most used programming language is a bit subjective and can depend on various factors such as the source, the time frame, and the type of applications. However, based on various surveys, indices, and other metrics, here are some of the most popular programming languages:\n",
            "\n",
            "**2022 Programming Language Rankings:**\n",
            "\n",
            "1. **JavaScript**: According to the TIOBE Index, JavaScript is the most popular programming language. It's widely used for web development, mobile app development, and server-side programming.\n",
            "2. **Python**: Python is a close second, widely used for data science, artificial intelligence, machine learning, web development, and scientific computing.\n",
            "3. **Java**: Java is a popular language for Android app development, web development, and enterprise software development.\n",
            "4. **C++**: C++ is a high-performance language used for game development, system programming, and other high-performance applications.\n",
            "5. **C#**: C# is a modern language used for Windows and web application development.\n",
            "\n",
            "**2022 Top 10 Programming Languages:**\n",
            "\n",
            "1. JavaScript (17.6%)\n",
            "2. Python (17.3%)\n",
            "3. Java (13.1%)\n",
            "4. C++ (11.4%)\n",
            "5. C# (8.2%)\n",
            "6. TypeScript (7.3%)\n",
            "7. PHP (6.6%)\n",
            "8. Swift (5.9%)\n",
            "9. Go (5.4%)\n",
            "10. Ruby (4.8%)\n",
            "\n",
            "**Note:** These rankings are based on various sources, including the TIOBE Index, GitHub, Stack Overflow, and Redmonk's Programming Language Rankings.\n",
            "\n",
            "Keep in mind that popularity can vary depending on the context, such as:\n",
            "\n",
            "* Web development: JavaScript, HTML/CSS, PHP, Ruby\n",
            "* Mobile app development: Java, Swift, Kotlin\n",
            "* Data science: Python, R, Julia\n",
            "* Game development: C++, Java, Python\n",
            "\n",
            "The popularity of programming languages can also change over time, so these rankings may not reflect the current situation in a few years.\n",
            "History: 1 messages, 1503 chars\n",
            "----------------------------------------------------------------------\n",
            "Run 9:\n",
            "User: Is Python better or R?\n",
            "Assistant: [Summary generated] I can't give a definitive answer to this question, as the choice between Python and R ultimately depends on your personal preferences, the specific tasks you're trying to accomplish, and the context in which you're working.\n",
            "\n",
            "Both languages have their strengths and weaknesses, and are widely used in different fields. Here's a brief comparison:\n",
            "\n",
            "**Python:**\n",
            "\n",
            "* Pros:\n",
            " + Easy to learn and use\n",
            " + Versatile and can be used for a wide range of tasks (web development, data science, machine learning, automation, etc.)\n",
            " + Large community and extensive libraries (e.g., NumPy, pandas, scikit-learn)\n",
            " + Fast execution and easy integration with other languages\n",
            "* Cons:\n",
            " + Can be slow for certain tasks, especially when working with large datasets\n",
            " + Not ideal for real-time data analysis or high-frequency trading\n",
            "\n",
            "**R:**\n",
            "\n",
            "* Pros:\n",
            " + Specialized for statistical computing and data visualization\n",
            " + Excellent for data analysis, machine learning, and data visualization\n",
            " + Large collection of libraries and packages (e.g., dplyr, tidyr, ggplot2)\n",
            " + Well-suited for data exploration and hypothesis testing\n",
            "* Cons:\n",
            " + Can be steep learning curve for beginners\n",
            " + Not as versatile as Python for tasks outside of data science\n",
            " + Slow execution for certain tasks\n",
            "\n",
            "Consider the following questions to help you decide between Python and R:\n",
            "\n",
            "* Are you working with data? If so, R might be a better choice due to its extensive libraries and expertise in statistical computing.\n",
            "* Do you need to perform machine learning tasks? Python has a broader range of machine learning libraries and tools.\n",
            "* Are you interested in web development or automation? Python is generally a better choice.\n",
            "* Are you working with real-time data analysis or high-frequency trading? R might not be the best choice due to its slow execution.\n",
            "\n",
            "Ultimately, the choice between Python and R depends on your specific needs and goals. You can also consider using both languages, as many data scientists and analysts do.\n",
            "History: 1 messages, 1503 chars\n",
            "📝 Summary generated after 9 runs!\n",
            "Latest summary: Here's a concise summary of the conversation:\n",
            "\n",
            "The conversation started with the user asking about t...\n",
            "----------------------------------------------------------------------\n",
            "Run 10:\n",
            "User: Difference between Machine Learning and Artificial Intelligence?\n",
            "Assistant: Machine Learning (ML) and Artificial Intelligence (AI) are often used interchangeably, but they have distinct meanings.\n",
            "\n",
            "**Artificial Intelligence (AI):**\n",
            "\n",
            "Artificial Intelligence refers to the broader field of research and development aimed at creating machines that can perform tasks that would typically require human intelligence. AI involves the creation of intelligent machines that can think, learn, and behave like humans. The ultimate goal of AI is to create intelligent systems that can perform a wide range of tasks, from simple to complex, without human intervention.\n",
            "\n",
            "AI encompasses various subfields, including:\n",
            "\n",
            "1. **Machine Learning (ML)**: AI's subset that focuses on developing algorithms and statistical models that enable machines to learn from data, make decisions, and improve their performance over time.\n",
            "2. **Natural Language Processing (NLP)**: AI's subset that deals with the interaction between computers and humans in natural language.\n",
            "3. **Computer Vision**: AI's subset that focuses on enabling machines to interpret and understand visual data from images and videos.\n",
            "4. **Robotics**: AI's subset that involves the design, construction, and operation of robots that can perform tasks autonomously.\n",
            "\n",
            "**Machine Learning (ML):**\n",
            "\n",
            "Machine Learning is a subset of AI that specifically deals with the development of algorithms and statistical models that enable machines to learn from data, make decisions, and improve their performance over time. ML involves training models on large datasets to enable them to recognize patterns, make predictions, and classify data.\n",
            "\n",
            "The goal of ML is to enable machines to learn from experience, without being explicitly programmed for each task. ML is used in many applications, including:\n",
            "\n",
            "1. **Predictive modeling**: ML algorithms are used to predict future outcomes based on historical data.\n",
            "2. **Classification**: ML algorithms are used to classify data into categories or classes.\n",
            "3. **Regression analysis**: ML algorithms are used to analyze the relationship between variables.\n",
            "4. **Clustering**: ML algorithms are used to group similar data points together.\n",
            "\n",
            "Key differences between Machine Learning and Artificial Intelligence:\n",
            "\n",
            "1. **Scope**: AI is a broader field that encompasses ML, while ML is a subset of AI.\n",
            "2. **Goals**: AI aims to create intelligent machines that can perform a wide range of tasks, while ML focuses on developing algorithms and statistical models that enable machines to learn from data.\n",
            "3. **Techniques**: AI involves a range of techniques, including rule-based systems, expert systems, and knowledge-based systems, while ML relies on statistical models and algorithms to learn from data\n",
            "History: 1 messages, 1503 chars\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "=== Truncation Settings Demonstration ===\n",
            "\n",
            "1. Turn-based truncation (last 3 messages):\n",
            "assistant : Machine Learning (ML) and Artificial Intelligence (AI) are often used ...\n",
            "\n",
            "2. Character-based truncation (500 chars):\n",
            "Total characters: 503\n",
            "assistant : Machine Learning (ML) and Artificial Intelligence (AI) are often used ...\n",
            "\n",
            "3. Combined truncation (last 4 messages, max 800 chars):\n",
            "Total characters: 803\n",
            "assistant : Machine Learning (ML) and Artificial Intelligence (AI) are often used ...\n",
            "\n",
            "=== All Summaries Generated ===\n",
            "\n",
            "Summary 1:\n",
            "Here's a concise summary of the conversation:\n",
            "\n",
            "The conversation started with the user asking about the current weather. The assistant explained that it doesn't have real-time access to weather informa...\n",
            "\n",
            "Summary 2:\n",
            "Here's a concise summary of the conversation:\n",
            "\n",
            "The conversation started with the user asking about the capital of India, which the assistant answered as New Delhi. The assistant then listed some of In...\n",
            "\n",
            "Summary 3:\n",
            "Here's a concise summary of the conversation:\n",
            "\n",
            "The conversation started with the user asking about the capital of India and then shifted to discussing new smartphones. The assistant provided informati...\n",
            "\n",
            "=== Final Conversation History ===\n",
            "Final stats: 1 messages, 1503 chars, 3 summaries\n",
            " 1. assistant : Machine Learning (ML) and Artificial Intelligence (AI) are often used interchangeably, but they have...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2**"
      ],
      "metadata": {
        "id": "p91nJPdRV8fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"## Task 2: JSON Extraction (Prompt-based, Compatible with Groq)\"\"\"\n",
        "\n",
        "import json\n",
        "import time\n",
        "from typing import Dict, Any\n",
        "\n",
        "# JSON Schema for reference/validation\n",
        "USER_INFO_SCHEMA = {\n",
        "    \"name\": \"extract_user_information\",\n",
        "    \"description\": \"Extract personal information from user messages\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\": \"string\"},\n",
        "            \"email\": {\"type\": \"string\"},\n",
        "            \"phone\": {\"type\": \"string\"},\n",
        "            \"location\": {\"type\": \"string\"},\n",
        "            \"age\": {\"type\": \"integer\"}\n",
        "        },\n",
        "        \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "class InformationExtractorPrompt:\n",
        "    def __init__(self, model: str = \"llama-3.1-8b-instant\"):  # Use specific model\n",
        "        self.model = model\n",
        "\n",
        "    def extract_information(self, user_message: str) -> Dict[str, Any]:\n",
        "        \"\"\"Prompt-based extraction returning JSON\"\"\"\n",
        "        prompt = f\"\"\"\n",
        "Extract the following details from the user message in JSON format:\n",
        "- name (string)\n",
        "- email (string)\n",
        "- phone (string)\n",
        "- location (string)\n",
        "- age (integer)\n",
        "\n",
        "If a field is missing, set it to null.\n",
        "\n",
        "Return ONLY valid JSON without any additional text.\n",
        "\n",
        "User message: \"{user_message}\"\n",
        "\n",
        "JSON:\n",
        "\"\"\"\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0,\n",
        "                max_tokens=500\n",
        "            )\n",
        "\n",
        "            # Parse JSON from assistant response\n",
        "            response_text = response.choices[0].message.content.strip()\n",
        "\n",
        "            # Clean the response (remove markdown code blocks if present)\n",
        "            if response_text.startswith(\"```json\"):\n",
        "                response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif response_text.startswith(\"```\"):\n",
        "                response_text = response_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "            extracted = json.loads(response_text)\n",
        "            return extracted\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            return {\"error\": \"Failed to parse JSON from response\"}\n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def validate_extraction(self, extracted_data: Dict[str, Any]):\n",
        "        \"\"\"Validate extracted data against schema\"\"\"\n",
        "        if \"error\" in extracted_data:\n",
        "            return [extracted_data[\"error\"]]\n",
        "\n",
        "        validation_errors = []\n",
        "        for field in USER_INFO_SCHEMA[\"parameters\"][\"properties\"]:\n",
        "            if field not in extracted_data or extracted_data[field] is None:\n",
        "                validation_errors.append(f\"Missing required field: {field}\")\n",
        "\n",
        "        # Basic email check\n",
        "        email = extracted_data.get(\"email\")\n",
        "        if email and email != \"null\" and (\"@\" not in email or \".\" not in email):\n",
        "            validation_errors.append(\"Invalid email format\")\n",
        "\n",
        "        # Age check\n",
        "        age = extracted_data.get(\"age\")\n",
        "        if age and age != \"null\":\n",
        "            try:\n",
        "                age_int = int(age)\n",
        "                if age_int <= 0 or age_int > 120:\n",
        "                    validation_errors.append(\"Age must be between 1 and 120\")\n",
        "            except (ValueError, TypeError):\n",
        "                validation_errors.append(\"Age must be a valid integer\")\n",
        "\n",
        "        return validation_errors"
      ],
      "metadata": {
        "id": "QdQ8bD8WMhOH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Demonstration for Task 2**"
      ],
      "metadata": {
        "id": "NPWxMXBWWNwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"### Demonstration of Task 2\"\"\"\n",
        "\n",
        "# Initialize extractor with a specific model to avoid rate limits\n",
        "extractor_prompt = InformationExtractorPrompt(model=\"llama-3.1-8b-instant\")\n",
        "\n",
        "# Sample chats\n",
        "sample_chats = [\n",
        "    \"Hi, my name is John Doe. I'm 25 years old from New York. My email is john.doe@email.com and phone is 555-1234.\",\n",
        "    \"I'm Sarah Smith, 30 years old. You can reach me at sarah.smith@company.com or 555-9876. I live in Los Angeles.\",\n",
        "    \"My contact info: Mike Johnson, mike.j@test.org, 555-5678. Age 35, based in Chicago.\"\n",
        "]\n",
        "\n",
        "print(\"=== Task 2 Demonstration: Information Extraction ===\\n\")\n",
        "\n",
        "for i, chat in enumerate(sample_chats, 1):\n",
        "    print(f\"Sample {i}: {chat}\")\n",
        "\n",
        "    # Add delay to avoid rate limiting\n",
        "    if i > 1:\n",
        "        time.sleep(1)\n",
        "\n",
        "    extracted = extractor_prompt.extract_information(chat)\n",
        "\n",
        "    if \"error\" in extracted:\n",
        "        print(f\"❌ Extraction failed: {extracted['error']}\")\n",
        "        # If it's a rate limit error, wait longer\n",
        "        if \"rate_limit\" in str(extracted['error']).lower() or \"429\" in str(extracted['error']):\n",
        "            print(\"⚠️ Rate limit detected, waiting 5 seconds...\")\n",
        "            time.sleep(5)\n",
        "            # Try one more time\n",
        "            extracted = extractor_prompt.extract_information(chat)\n",
        "    else:\n",
        "        print(\"✅ Extracted data:\")\n",
        "        for k, v in extracted.items():\n",
        "            print(f\"   {k}: {v}\")\n",
        "\n",
        "        # Validate\n",
        "        errors = extractor_prompt.validate_extraction(extracted)\n",
        "        if errors:\n",
        "            print(\"❌ Validation errors:\")\n",
        "            for err in errors:\n",
        "                print(f\"   - {err}\")\n",
        "        else:\n",
        "            print(\"✅ All validations passed!\")\n",
        "\n",
        "    print(\"-\"*60)\n",
        "\n",
        "\"\"\"### Integration Example: Conversation + Extraction\"\"\"\n",
        "\n",
        "print(\"=== Integration Example: Combined Conversation and Extraction ===\\n\")\n",
        "\n",
        "# Create a simple conversation manager for demonstration\n",
        "class SimpleConversationManager:\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "\n",
        "    def add_message(self, role, content):\n",
        "        self.history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "    def get_response(self, user_input):\n",
        "        self.add_message(\"user\", user_input)\n",
        "\n",
        "        # Simple echo response for demonstration\n",
        "        response = f\"I received your message: {user_input}\"\n",
        "        self.add_message(\"assistant\", response)\n",
        "        return response\n",
        "\n",
        "# Use simple manager to avoid API calls\n",
        "integrated_manager = SimpleConversationManager()\n",
        "\n",
        "# Simulate conversation including personal info\n",
        "integrated_chats = [\n",
        "    \"Hello, I need help with my account.\",\n",
        "    \"My name is Emily Chen and I'm 28 years old.\",\n",
        "    \"My email is emily.chen@example.com and I live in Seattle.\",\n",
        "    \"Can you help me reset my password?\",\n",
        "    \"My phone number is 555-2468 if you need to contact me.\"\n",
        "]\n",
        "\n",
        "for i, chat in enumerate(integrated_chats, 1):\n",
        "    print(f\"User {i}: {chat}\")\n",
        "\n",
        "    # Extract info if chat contains personal data\n",
        "    if any(keyword in chat.lower() for keyword in [\"name\", \"email\", \"phone\", \"age\", \"live\"]):\n",
        "        extracted = extractor_prompt.extract_information(chat)\n",
        "        if \"error\" not in extracted:\n",
        "            print(f\"📋 Extracted info: {extracted}\")\n",
        "        else:\n",
        "            print(f\"⚠️ Extraction failed: {extracted['error']}\")\n",
        "\n",
        "    # Continue conversation (simple echo for demonstration)\n",
        "    response = integrated_manager.get_response(chat)\n",
        "    print(f\"Assistant: {response[:100]}...\\n\")\n",
        "    print(\"-\"*40)\n",
        "\n",
        "\"\"\"### Alternative: Manual JSON Extraction (Fallback)\"\"\"\n",
        "\n",
        "def manual_extract_information(text):\n",
        "    \"\"\"Manual extraction as fallback when API fails\"\"\"\n",
        "    result = {\n",
        "        \"name\": None,\n",
        "        \"email\": None,\n",
        "        \"phone\": None,\n",
        "        \"location\": None,\n",
        "        \"age\": None\n",
        "    }\n",
        "\n",
        "    # Simple pattern matching (for demonstration)\n",
        "    import re\n",
        "\n",
        "    # Extract name (simple pattern)\n",
        "    name_match = re.search(r'(?:name is|my name is|I\\'m) ([A-Za-z]+ [A-Za-z]+)', text, re.IGNORECASE)\n",
        "    if name_match:\n",
        "        result[\"name\"] = name_match.group(1)\n",
        "\n",
        "    # Extract email\n",
        "    email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', text)\n",
        "    if email_match:\n",
        "        result[\"email\"] = email_match.group(0)\n",
        "\n",
        "    # Extract phone\n",
        "    phone_match = re.search(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', text)\n",
        "    if phone_match:\n",
        "        result[\"phone\"] = phone_match.group(0)\n",
        "\n",
        "    # Extract age\n",
        "    age_match = re.search(r'(\\d+)(?=\\s*years? old)', text, re.IGNORECASE)\n",
        "    if age_match:\n",
        "        result[\"age\"] = int(age_match.group(1))\n",
        "\n",
        "    # Extract location\n",
        "    locations = [\"New York\", \"Los Angeles\", \"Chicago\", \"Seattle\", \"Boston\"]\n",
        "    for loc in locations:\n",
        "        if loc.lower() in text.lower():\n",
        "            result[\"location\"] = loc\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "# Test manual extraction\n",
        "print(\"=== Manual Extraction Test ===\\n\")\n",
        "for i, chat in enumerate(sample_chats, 1):\n",
        "    print(f\"Sample {i}: {chat}\")\n",
        "    manual_result = manual_extract_information(chat)\n",
        "    print(f\"Manual extraction: {manual_result}\")\n",
        "    print(\"-\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lxrMOsGLscM",
        "outputId": "92766cd8-a7ec-4ac4-c71b-4c3a22706bea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Task 2 Demonstration: Information Extraction ===\n",
            "\n",
            "Sample 1: Hi, my name is John Doe. I'm 25 years old from New York. My email is john.doe@email.com and phone is 555-1234.\n",
            "✅ Extracted data:\n",
            "   name: John Doe\n",
            "   email: john.doe@email.com\n",
            "   phone: 555-1234\n",
            "   location: New York\n",
            "   age: 25\n",
            "✅ All validations passed!\n",
            "------------------------------------------------------------\n",
            "Sample 2: I'm Sarah Smith, 30 years old. You can reach me at sarah.smith@company.com or 555-9876. I live in Los Angeles.\n",
            "✅ Extracted data:\n",
            "   name: Sarah Smith\n",
            "   email: sarah.smith@company.com\n",
            "   phone: 555-9876\n",
            "   location: Los Angeles\n",
            "   age: 30\n",
            "✅ All validations passed!\n",
            "------------------------------------------------------------\n",
            "Sample 3: My contact info: Mike Johnson, mike.j@test.org, 555-5678. Age 35, based in Chicago.\n",
            "✅ Extracted data:\n",
            "   name: Mike Johnson\n",
            "   email: mike.j@test.org\n",
            "   phone: 555-5678\n",
            "   location: Chicago\n",
            "   age: 35\n",
            "✅ All validations passed!\n",
            "------------------------------------------------------------\n",
            "=== Integration Example: Combined Conversation and Extraction ===\n",
            "\n",
            "User 1: Hello, I need help with my account.\n",
            "Assistant: I received your message: Hello, I need help with my account....\n",
            "\n",
            "----------------------------------------\n",
            "User 2: My name is Emily Chen and I'm 28 years old.\n",
            "📋 Extracted info: {'name': 'Emily Chen', 'email': None, 'phone': None, 'location': None, 'age': 28}\n",
            "Assistant: I received your message: My name is Emily Chen and I'm 28 years old....\n",
            "\n",
            "----------------------------------------\n",
            "User 3: My email is emily.chen@example.com and I live in Seattle.\n",
            "📋 Extracted info: {'name': 'Emily Chen', 'email': 'emily.chen@example.com', 'phone': None, 'location': 'Seattle', 'age': None}\n",
            "Assistant: I received your message: My email is emily.chen@example.com and I live in Seattle....\n",
            "\n",
            "----------------------------------------\n",
            "User 4: Can you help me reset my password?\n",
            "Assistant: I received your message: Can you help me reset my password?...\n",
            "\n",
            "----------------------------------------\n",
            "User 5: My phone number is 555-2468 if you need to contact me.\n",
            "📋 Extracted info: {'name': None, 'email': None, 'phone': '555-2468', 'location': None, 'age': None}\n",
            "Assistant: I received your message: My phone number is 555-2468 if you need to contact me....\n",
            "\n",
            "----------------------------------------\n",
            "=== Manual Extraction Test ===\n",
            "\n",
            "Sample 1: Hi, my name is John Doe. I'm 25 years old from New York. My email is john.doe@email.com and phone is 555-1234.\n",
            "Manual extraction: {'name': 'John Doe', 'email': 'john.doe@email.com', 'phone': None, 'location': 'New York', 'age': 25}\n",
            "----------------------------------------\n",
            "Sample 2: I'm Sarah Smith, 30 years old. You can reach me at sarah.smith@company.com or 555-9876. I live in Los Angeles.\n",
            "Manual extraction: {'name': 'Sarah Smith', 'email': 'sarah.smith@company.com', 'phone': None, 'location': 'Los Angeles', 'age': 30}\n",
            "----------------------------------------\n",
            "Sample 3: My contact info: Mike Johnson, mike.j@test.org, 555-5678. Age 35, based in Chicago.\n",
            "Manual extraction: {'name': None, 'email': 'mike.j@test.org', 'phone': None, 'location': 'Chicago', 'age': None}\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}